import "lexer.omni";
import "token.omni";
import "ast.omni";

struct Parser {
    lexer: Lexer,
    cur_token: Token,
    peek_token: Token
}

fn new_parser(l: Lexer) -> Parser {
    let p = Parser {
        lexer: l,
        cur_token: new_token(0, "", 0),
        peek_token: new_token(0, "", 0)
    };
    Parser_next_token(p);
    Parser_next_token(p);
    return p;
}

fn Parser_next_token(p: Parser) {
    p.cur_token = p.peek_token;
    p.peek_token = Lexer_next_token(p.lexer);
}

fn Parser_parse_program(p: Parser) -> Program {
    let stmts = [];
    while (p.cur_token.kind != TOKEN_EOF) {
        let stmt = Parser_parse_statement(p);
        if (stmt.kind != 0) {
            native "js" { stmts.push(stmt); }
        }
        Parser_next_token(p);
    }
    return Program { statements: stmts };
}

fn Parser_parse_statement(p: Parser) -> any {
    if (p.cur_token.kind == 90) { // TOKEN_IMPORT
        return Parser_parse_import(p);
    }
    if (p.cur_token.kind == TOKEN_LET) {
        return Parser_parse_let(p);
    }
    if (p.cur_token.kind == TOKEN_FN) {
        return Parser_parse_fn(p);
    }
    if (p.cur_token.kind == TOKEN_STRUCT) {
        return Parser_parse_struct(p);
    }
    if (p.cur_token.kind == TOKEN_RETURN) {
        return Parser_parse_return(p);
    }
    if (p.cur_token.kind == TOKEN_NATIVE) {
        return Parser_parse_native_block(p);
    }
    return Parser_parse_expr_stmt(p);
}

fn Parser_parse_import(p: Parser) -> ImportDecl {
    // import "path";
    Parser_next_token(p); // skip import
    let path = p.cur_token.lexeme;
    Parser_next_token(p); // skip path string
    // skip ; if exists
    if (p.cur_token.kind == TOKEN_SEMICOLON) {
        // will be consumed by main loop's Parser_next_token
    }
    return ImportDecl { kind: NODE_IMPORT, path: path };
}

fn Parser_parse_let(p: Parser) -> LetStmt {
    Parser_next_token(p); // skip let
    let name = p.cur_token.lexeme;
    Parser_next_token(p); // skip name
    
    // Handle optional type annotation: let x: Type = ...
    if (p.cur_token.kind == 30) { // TOKEN_COLON
        Parser_next_token(p); // skip :
        Parser_next_token(p); // skip type
    }
    
    Parser_next_token(p); // skip =
    let val = Parser_parse_expression(p);
    
    if (p.cur_token.kind == TOKEN_SEMICOLON) {
        // consumed by main loop
    }
    return LetStmt { kind: NODE_LET, name: name, value: val };
}

fn Parser_parse_return(p: Parser) -> ReturnStmt {
    Parser_next_token(p); // skip return
    let val = Parser_parse_expression(p);
    if (p.cur_token.kind == TOKEN_SEMICOLON) {
        // consumed by main loop
    }
    return ReturnStmt { kind: NODE_RETURN, value: val };
}

fn Parser_parse_fn(p: Parser) -> FunctionDecl {
    Parser_next_token(p); // skip fn
    let name = p.cur_token.lexeme;
    Parser_next_token(p); // skip name
    Parser_next_token(p); // skip (
    
    let params = [];
    while (p.cur_token.kind != TOKEN_RPAREN) {
        native "js" { params.push(p.cur_token.lexeme); }
        Parser_next_token(p);
        // Skip type annotation if exists
        if (p.cur_token.kind == 30) { // TOKEN_COLON
            Parser_next_token(p); // skip :
            Parser_next_token(p); // skip type
        }
        if (p.cur_token.kind == TOKEN_COMMA) {
            Parser_next_token(p);
        }
    }
    Parser_next_token(p); // skip )
    
    // Handle return type annotation: -> Type
    if (p.cur_token.lexeme == "-") {
        Parser_next_token(p); // skip -
        Parser_next_token(p); // skip >
        Parser_next_token(p); // skip return type
    }
    
    let body = Parser_parse_block(p);
    return FunctionDecl { kind: NODE_FUNCTION, name: name, params: params, body: body };
}

fn Parser_parse_struct(p: Parser) -> StructDecl {
    Parser_next_token(p); // skip struct
    let name = p.cur_token.lexeme;
    Parser_next_token(p); // skip name
    Parser_next_token(p); // skip {
    
    let fields = [];
    while (p.cur_token.kind != TOKEN_RBRACE && p.cur_token.kind != TOKEN_EOF) {
        let field_name = p.cur_token.lexeme;
        Parser_next_token(p); // skip field_name
        Parser_next_token(p); // skip :
        let field_type = p.cur_token.lexeme;
        Parser_next_token(p); // skip type
        
        let f = new_struct_field(field_name, field_type);
        native "js" { fields.push(f); }
        
        if (p.cur_token.kind == TOKEN_COMMA) {
            Parser_next_token(p);
        }
    }
    // Don't consume } here, let main loop handle it
    
    return StructDecl { kind: NODE_STRUCT, name: name, fields: fields };
}

fn Parser_parse_native_block(p: Parser) -> NativeStmt {
    Parser_next_token(p); // skip native
    
    let lang = "js";
    if (p.cur_token.kind == TOKEN_STRING) {
        lang = p.cur_token.lexeme;
        Parser_next_token(p); // skip language string
    }
    
    if (p.cur_token.kind != TOKEN_LBRACE) {
        return NativeStmt { kind: 0, lang: "", code: "" };
    }
    
    let start_pos = p.cur_token.start;
    let code = "";
    let end_pos = 0;
    
    native "js" {
        const input = p.lexer.input;
        let pos = Number(start_pos) + 1;
        let brace_count = 1;
        let start_extract = pos;
        
        while (pos < input.length && brace_count > 0) {
            const char = input[pos];
            if (char === '{') brace_count++;
            if (char === '}') brace_count--;
            pos++;
        }
        
        end_pos = pos;
        if (brace_count === 0) {
            code = input.substring(start_extract, pos - 1);
        }
    }
    
    // Update lexer position
    native "js" {
        p.lexer.read_position = end_pos;
    }
    Lexer_read_char(p.lexer);
    p.peek_token = Lexer_next_token(p.lexer);
    
    return NativeStmt { kind: NODE_NATIVE, lang: lang, code: code };
}

fn Parser_parse_block(p: Parser) -> Block {
    Parser_next_token(p); // skip {
    let stmts = [];
    while (p.cur_token.kind != TOKEN_RBRACE && p.cur_token.kind != TOKEN_EOF) {
        let stmt = Parser_parse_statement(p);
        native "js" { stmts.push(stmt); }
        Parser_next_token(p);
    }
    // Don't consume } here
    return Block { kind: NODE_BLOCK, statements: stmts };
}

fn Parser_parse_expr_stmt(p: Parser) -> ExpressionStmt {
    let expr = Parser_parse_expression(p);
    if (p.cur_token.kind == TOKEN_SEMICOLON) {
        // consumed by main loop
    }
    return ExpressionStmt { kind: 0, expr: expr };
}

// Expression Parsing with Precedence
fn Parser_parse_expression(p: Parser) -> any {
    return Parser_parse_equality(p);
}

fn Parser_parse_equality(p: Parser) -> any {
    let left = Parser_parse_term(p);
    
    while (p.cur_token.kind == TOKEN_EQ || p.cur_token.kind == TOKEN_NOT_EQ) {
        let op = p.cur_token.lexeme;
        Parser_next_token(p);
        let right = Parser_parse_term(p);
        left = BinaryExpr { kind: NODE_BINARY, left: left, op: op, right: right };
    }
    return left;
}

fn Parser_parse_term(p: Parser) -> any {
    let left = Parser_parse_factor(p);
    
    while (p.cur_token.kind == TOKEN_PLUS || p.cur_token.kind == TOKEN_MINUS) {
        let op = p.cur_token.lexeme;
        Parser_next_token(p);
        let right = Parser_parse_factor(p);
        left = BinaryExpr { kind: NODE_BINARY, left: left, op: op, right: right };
    }
    return left;
}

fn Parser_parse_factor(p: Parser) -> any {
    let node: any = 0;
    
    if (p.cur_token.kind == TOKEN_INT) {
        let val = 0;
        native "js" { val = parseInt(p.cur_token.lexeme); }
        node = IntegerLiteral { kind: NODE_LITERAL, value: val };
        Parser_next_token(p);
    } else if (p.cur_token.kind == TOKEN_IDENTIFIER) {
        let name = p.cur_token.lexeme;
        Parser_next_token(p);
        
        if (p.cur_token.kind == TOKEN_LPAREN) {
            Parser_next_token(p); // skip (
            let args = [];
            while (p.cur_token.kind != TOKEN_RPAREN) {
                native "js" { args.push(Parser_parse_expression(p)); }
                if (p.cur_token.kind == TOKEN_COMMA) {
                    Parser_next_token(p);
                }
            }
            Parser_next_token(p); // skip )
            node = CallExpr { kind: NODE_CALL, function: name, args: args };
        } else if (p.cur_token.kind == TOKEN_LBRACE) {
            // Struct instantiation: Name { field: value }
            Parser_next_token(p); // skip {
            let init_fields = [];
            while (p.cur_token.kind != TOKEN_RBRACE && p.cur_token.kind != TOKEN_EOF) {
                let field_name = p.cur_token.lexeme;
                Parser_next_token(p); // skip field name
                Parser_next_token(p); // skip :
                let field_val = Parser_parse_expression(p);
                native "js" { init_fields.push({ name: field_name, value: field_val }); }
                if (p.cur_token.kind == TOKEN_COMMA) {
                    Parser_next_token(p);
                }
            }
            Parser_next_token(p); // skip }
            native "js" { node = { kind: NODE_STRUCT_INIT, name: name, fields: init_fields }; }
        } else {
            node = name; // identifier
        }
    } else if (p.cur_token.kind == TOKEN_LPAREN) {
        Parser_next_token(p); // skip (
        node = Parser_parse_expression(p);
        Parser_next_token(p); // skip )
    } else if (p.cur_token.kind == TOKEN_STRING) {
        native "js" { node = { kind: NODE_LITERAL, value: `"${p.cur_token.lexeme}"` }; }
        Parser_next_token(p);
    } else if (p.cur_token.kind == TOKEN_LBRACKET) {
        // Array literal: []
        Parser_next_token(p); // skip [
        let elements = [];
        while (p.cur_token.kind != TOKEN_RBRACKET && p.cur_token.kind != TOKEN_EOF) {
            native "js" { elements.push(Parser_parse_expression(p)); }
            if (p.cur_token.kind == TOKEN_COMMA) {
                Parser_next_token(p);
            }
        }
        Parser_next_token(p); // skip ]
        native "js" { node = { kind: NODE_ARRAY, elements: elements }; }
    }
    
    // Member access loop
    while (p.cur_token.kind == 31) { // TOKEN_DOT
        Parser_next_token(p); // skip .
        let prop = p.cur_token.lexeme;
        Parser_next_token(p); // skip property
        node = MemberExpr { kind: NODE_MEMBER, target: node, property: prop };
    }
    
    return node;
}